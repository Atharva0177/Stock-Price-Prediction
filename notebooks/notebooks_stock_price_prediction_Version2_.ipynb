{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Stock Price Prediction with LSTM\n",
    "\n",
    "This notebook demonstrates end-to-end stock price prediction using LSTM neural networks.\n",
    "\n",
    "## Objectives:\n",
    "- Fetch historical stock data from Yahoo Finance\n",
    "- Engineer technical indicators (MA, RSI, MACD)\n",
    "- Build and train LSTM model\n",
    "- Evaluate model performance\n",
    "- Make future price predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# ! pip install yfinance pandas numpy keras tensorflow scikit-learn matplotlib seaborn plotly\n",
    "\n",
    "import warnings\n",
    "warnings. filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import custom modules\n",
    "from data_fetcher import StockDataFetcher\n",
    "from feature_engineering import FeatureEngineer\n",
    "from preprocessor import DataPreprocessor\n",
    "from model import LSTMModel\n",
    "from trainer import ModelTrainer\n",
    "from visualizer import Visualizer\n",
    "import config\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt. style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "\n",
    "Fetch historical stock data from Yahoo Finance API."
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "TICKER = 'AAPL'  # Change to any stock ticker\n",
    "PERIOD = '5y'    # 5 years of data\n",
    "\n",
    "# Initialize data fetcher\n",
    "fetcher = StockDataFetcher(cache_dir='../data/')\n",
    "\n",
    "# Fetch data\n",
    "print(f\"Fetching data for {TICKER}...\")\n",
    "df = fetcher.fetch_stock_data(TICKER, period=PERIOD)\n",
    "\n",
    "# Get stock information\n",
    "stock_info = fetcher.get_stock_info(TICKER)\n",
    "\n",
    "print(f\"\\nüìä Stock:  {stock_info['name']}\")\n",
    "print(f\"üìÖ Data Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"üìà Total Records: {len(df)}\")\n",
    "print(f\"\\nStock Info:\")\n",
    "for key, value in stock_info. items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first and last rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Statistical Summary:\")\n",
    "df[['Open', 'High', 'Low', 'Close', 'Volume']].describe()"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price history\n",
    "fig = Visualizer.plot_price_history(df, TICKER)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Close price distribution\n",
    "axes[0].hist(df['Close'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Close Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Price ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume distribution\n",
    "axes[1].hist(df['Volume'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Volume Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Volume')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = df[['Open', 'High', 'Low', 'Close', 'Volume']].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Add technical indicators to enhance prediction capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer()\n",
    "\n",
    "# Add all technical indicators\n",
    "print(\"Adding technical indicators...\")\n",
    "df = engineer.add_all_indicators(df, ma_windows=[50, 200], rsi_period=14)\n",
    "\n",
    "print(f\"\\n‚úÖ Features added! \")\n",
    "print(f\"Total features: {len(df.columns)}\")\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Display data with indicators\n",
    "print(\"Data with Technical Indicators:\")\n",
    "display(df[['Date', 'Close', 'MA_50', 'MA_200', 'RSI', 'MACD', 'MACD_Signal']].tail(10))"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize technical indicators\n",
    "fig = Visualizer.plot_technical_indicators(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "## 5. Data Preprocessing\n",
    "\n",
    "Normalize data and create sequences for LSTM input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Select features for training\n",
    "FEATURES = config.FEATURES\n",
    "TARGET = config.TARGET\n",
    "SEQ_LENGTH = config.SEQ_LENGTH\n",
    "TEST_SIZE = config.TEST_SIZE\n",
    "\n",
    "print(f\"Selected features: {FEATURES}\")\n",
    "print(f\"Target:  {TARGET}\")\n",
    "print(f\"Sequence length: {SEQ_LENGTH} days\")\n",
    "print(f\"Test size: {TEST_SIZE * 100}%\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor(FEATURES, TARGET)\n",
    "\n",
    "# Normalize data\n",
    "print(\"Normalizing data...\")\n",
    "features, target, original_df = preprocessor.normalize_data(df)\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target shape: {target. shape}\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "print(\"Creating sequences... \")\n",
    "X, y = preprocessor.create_sequences(features, target, SEQ_LENGTH)\n",
    "\n",
    "print(f\"X shape: {X.shape} (samples, timesteps, features)\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = preprocessor.train_test_split(X, y, TEST_SIZE)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nTraining set date range: {df['Date'].iloc[SEQ_LENGTH: SEQ_LENGTH+len(X_train)].min()} to {df['Date'].iloc[SEQ_LENGTH:SEQ_LENGTH+len(X_train)].max()}\")\n",
    "print(f\"Testing set date range: {df['Date'].iloc[-len(X_test):].min()} to {df['Date'].iloc[-len(X_test):].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building\n",
    "\n",
    "Build LSTM neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Initialize LSTM model\n",
    "lstm_model = LSTMModel(\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    n_features=len(FEATURES),\n",
    "    lstm_units=config.LSTM_UNITS,\n",
    "    dropout_rate=config.DROPOUT_RATE,\n",
    "    learning_rate=config.LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Build model\n",
    "model = lstm_model.build_model()\n",
    "\n",
    "print(\"\\nüìä Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Explanation:\n",
    "\n",
    "- **Input Layer**: Takes sequences of 60 days with 5 features each\n",
    "- **LSTM Layer 1**: 50 units with return_sequences=True for stacking\n",
    "- **Dropout**:  20% dropout to prevent overfitting\n",
    "- **LSTM Layer 2**: 50 units for pattern learning\n",
    "- **Dropout**: Another 20% dropout layer\n",
    "- **Dense Layer**: 25 units with ReLU activation\n",
    "- **Output Layer**: Single unit for price prediction\n",
    "\n",
    "**Optimizer**: Adam with learning rate 0.001  \n",
    "**Loss Function**: Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training\n",
    "\n",
    "Train the model with early stopping and model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ModelTrainer(lstm_model)\n",
    "\n",
    "# Get callbacks\n",
    "callbacks = lstm_model.get_callbacks(model_path='../models/best_model.h5', patience=10)\n",
    "\n",
    "print(\"üöÄ Starting training...\\n\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = trainer.train(\n",
    "    X_train, y_train,\n",
    "    epochs=config.EPOCHS,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    validation_split=config.VALIDATION_SPLIT,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = Visualizer.plot_training_history(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and scalers\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "lstm_model.save_model('../models/lstm_stock_model.h5')\n",
    "preprocessor.save_scalers('../models/feature_scaler.pkl', '../models/target_scaler. pkl')\n",
    "\n",
    "print(\"‚úÖ Model and scalers saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n",
    "\n",
    "Evaluate model performance on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "metrics = trainer.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"\\nüìä Model Performance Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RMSE (Root Mean Squared Error): ${metrics['rmse']:.4f}\")\n",
    "print(f\"MAE (Mean Absolute Error):      ${metrics['mae']:.4f}\")\n",
    "print(f\"MAPE (Mean Absolute % Error):   {metrics['mape']:. 2f}%\")\n",
    "print(f\"R¬≤ Score:                        {metrics['r2']:.4f}\")\n",
    "print(f\"Direction Accuracy:              {metrics['direction_accuracy']:. 2f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata":  {},
   "source": [
    "## 9. Predictions & Visualization\n",
    "\n",
    "Make predictions and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = trainer.predict(X_test)\n",
    "\n",
    "# Inverse transform to get actual prices\n",
    "y_pred_actual = preprocessor.inverse_transform_target(y_pred)\n",
    "y_test_actual = preprocessor.inverse_transform_target(y_test)\n",
    "\n",
    "print(f\"Predictions shape: {y_pred_actual.shape}\")\n",
    "print(f\"First 5 predictions: \")\n",
    "for i in range(5):\n",
    "    print(f\"  Actual: ${y_test_actual[i][0]:.2f}, Predicted: ${y_pred_actual[i][0]:.2f}, Error: ${abs(y_test_actual[i][0] - y_pred_actual[i][0]):.2f}\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test dates\n",
    "test_dates = df['Date'].iloc[-len(y_test):].reset_index(drop=True)\n",
    "\n",
    "# Plot predictions vs actual\n",
    "fig = Visualizer.plot_predictions(y_test_actual, y_pred_actual, test_dates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction errors\n",
    "fig = Visualizer.plot_prediction_error(y_test_actual, y_pred_actual)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Date': test_dates,\n",
    "    'Actual':  y_test_actual. flatten(),\n",
    "    'Predicted': y_pred_actual.flatten(),\n",
    "    'Error': (y_test_actual - y_pred_actual).flatten(),\n",
    "    'Error_Percent': ((y_test_actual - y_pred_actual) / y_test_actual * 100).flatten()\n",
    "})\n",
    "\n",
    "print(\"\\nPrediction Comparison (Last 10 days):\")\n",
    "display(comparison_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "## 10. Future Predictions\n",
    "\n",
    "Predict stock prices for the next 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "# Predict future prices\n",
    "FUTURE_DAYS = 30\n",
    "\n",
    "print(f\"Predicting next {FUTURE_DAYS} days...\")\n",
    "\n",
    "# Get last sequence\n",
    "last_sequence = X[-1]\n",
    "\n",
    "# Make future predictions\n",
    "future_predictions = trainer.predict_future(last_sequence, FUTURE_DAYS, preprocessor)\n",
    "\n",
    "print(f\"Future predictions shape: {future_predictions. shape}\")"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future dates\n",
    "last_date = df['Date'].iloc[-1]\n",
    "future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=FUTURE_DAYS, freq='D')\n",
    "\n",
    "# Create forecast DataFrame\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Predicted_Price': future_predictions.flatten()\n",
    "})\n",
    "\n",
    "print(f\"\\nüìà {TICKER} Price Forecast for Next {FUTURE_DAYS} Days:\")\n",
    "display(forecast_df)"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot future predictions\n",
    "historical_prices = df['Close'].tail(90)\n",
    "historical_dates = df['Date'].tail(90)\n",
    "\n",
    "fig = Visualizer.plot_future_predictions(\n",
    "    historical_prices, \n",
    "    future_predictions. flatten(),\n",
    "    historical_dates, \n",
    "    future_dates, \n",
    "    TICKER\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast statistics\n",
    "current_price = df['Close'].iloc[-1]\n",
    "predicted_price_7d = future_predictions[6][0]\n",
    "predicted_price_30d = future_predictions[29][0]\n",
    "\n",
    "change_7d = predicted_price_7d - current_price\n",
    "change_7d_pct = (change_7d / current_price) * 100\n",
    "\n",
    "change_30d = predicted_price_30d - current_price\n",
    "change_30d_pct = (change_30d / current_price) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä {TICKER} Price Forecast Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Current Price:               ${current_price:.2f}\")\n",
    "print(f\"\\nPredicted Price (7 days):   ${predicted_price_7d:. 2f}\")\n",
    "print(f\"Change:                      ${change_7d:. 2f} ({change_7d_pct: +.2f}%)\")\n",
    "print(f\"\\nPredicted Price (30 days):  ${predicted_price_30d:.2f}\")\n",
    "print(f\"Change:                     ${change_30d:.2f} ({change_30d_pct:+. 2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Trend analysis\n",
    "if change_30d > 0:\n",
    "    print(\"\\nüìà Trend:  BULLISH (Upward trend predicted)\")\n",
    "else:\n",
    "    print(\"\\nüìâ Trend: BEARISH (Downward trend predicted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecast to CSV\n",
    "forecast_df.to_csv(f'../data/{TICKER}_forecast_{datetime.now().strftime(\"%Y%m%d\")}.csv', index=False)\n",
    "print(f\"\\n‚úÖ Forecast saved to ../data/{TICKER}_forecast_{datetime.now().strftime('%Y%m%d')}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source":  [
    "## 11. Model Analysis & Insights"
   ]
  },
  {
   "cell_type":  "code",
   "execution_count":  null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis (approximate)\n",
    "print(\"üìä Feature Analysis:\")\n",
    "print(\"\\nFeatures used in model:\")\n",
    "for i, feature in enumerate(FEATURES, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "print(\"\\nüí° Technical Indicator Insights:\")\n",
    "print(f\"  ‚Ä¢ MA_50 > MA_200: {'Golden Cross (Bullish)' if df['MA_50'].iloc[-1] > df['MA_200']. iloc[-1] else 'Death Cross (Bearish)'}\")\n",
    "print(f\"  ‚Ä¢ Current RSI: {df['RSI'].iloc[-1]:.2f} - {'Overbought' if df['RSI'].iloc[-1] > 70 else 'Oversold' if df['RSI'].iloc[-1] < 30 else 'Neutral'}\")\n",
    "print(f\"  ‚Ä¢ MACD Signal: {'Bullish' if df['MACD'].iloc[-1] > df['MACD_Signal'].iloc[-1] else 'Bearish'}\")"
   ]
  },
  {
   "cell_type":  "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion & Next Steps\n",
    "\n",
    "### Model Performance Summary:\n",
    "- Successfully built and trained LSTM model for stock price prediction\n",
    "- Achieved reasonable prediction accuracy on test data\n",
    "- Generated 30-day price forecasts\n",
    "\n",
    "### Limitations:\n",
    "1. **Market Volatility**: Model assumes patterns continue; unexpected events can cause large deviations\n",
    "2. **External Factors**: Doesn't account for news, earnings, economic indicators\n",
    "3. **Historical Bias**: Based solely on past data patterns\n",
    "4. **Feature Dependency**: Limited to technical indicators\n",
    "\n",
    "### Future Improvements:\n",
    "1. **Add More Features**:\n",
    "   - Sentiment analysis from news/social media\n",
    "   - Economic indicators (interest rates, GDP)\n",
    "   - Company fundamentals (P/E ratio, earnings)\n",
    "\n",
    "2. **Model Enhancements**:\n",
    "   - Bidirectional LSTM\n",
    "   - Attention mechanisms\n",
    "   - Ensemble methods (combining multiple models)\n",
    "   - GRU layers as alternative\n",
    "\n",
    "3. **Advanced Techniques**:\n",
    "   - Walk-forward validation\n",
    "   - Multi-step predictions\n",
    "   - Confidence intervals\n",
    "   - Anomaly detection\n",
    "\n",
    "4. **Deployment**:\n",
    "   - Real-time predictions\n",
    "   - Automated retraining\n",
    "   - Alert system for significant predictions\n",
    "\n",
    "### ‚ö†Ô∏è Disclaimer:\n",
    "**This model is for educational purposes only. Stock price predictions are inherently uncertain and should NOT be used as the sole basis for investment decisions.  Past performance does not guarantee future results.  Always consult with financial advisors and conduct thorough research before making investment decisions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs":  [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Notebook Execution Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Successfully: \")\n",
    "print(f\"  ‚Ä¢ Fetched {len(df)} days of {TICKER} stock data\")\n",
    "print(f\"  ‚Ä¢ Engineered {len(FEATURES)} technical indicators\")\n",
    "print(f\"  ‚Ä¢ Trained LSTM model for {config. EPOCHS} epochs\")\n",
    "print(f\"  ‚Ä¢ Achieved {metrics['direction_accuracy']:.2f}% direction accuracy\")\n",
    "print(f\"  ‚Ä¢ Generated {FUTURE_DAYS}-day price forecast\")\n",
    "print(f\"\\nüìÅ Saved Files:\")\n",
    "print(f\"  ‚Ä¢ Model: ../models/lstm_stock_model. h5\")\n",
    "print(f\"  ‚Ä¢ Scalers: ../models/*_scaler.pkl\")\n",
    "print(f\"  ‚Ä¢ Forecast: ../data/{TICKER}_forecast_*.csv\")\n",
    "print(\"\\nüöÄ Next:  Run the Streamlit dashboard with:  streamlit run ../app. py\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language":  "python",
   "name":  "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version":  3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor":  4
}
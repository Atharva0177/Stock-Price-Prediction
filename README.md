# ðŸ“ˆ Advanced Stock Price Prediction System with Deep Learning

A production-ready stock price prediction application powered by **PyTorch**, featuring 6 advanced deep learning models, GPU acceleration, real-time monitoring, and comprehensive technical analysis. Built with Streamlit for an intuitive Google Finance-style interface.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-orange)
![CUDA](https://img.shields.io/badge/CUDA-13.0-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.25%2B-red)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ðŸš€ Key Highlights

- **6 State-of-the-Art Models**: LSTM, Attention-LSTM, N-BEATS, TCN, Transformer, Ensemble
- **GPU Acceleration**: CUDA-optimized training with RTX 5070 support (11.94 GB VRAM)
- **Real-Time Monitoring**: Google Finance-style interface with live price updates
- **Interactive Candlestick Charts**: Support/resistance detection with pattern recognition
- **Model Comparison Dashboard**: Side-by-side performance analysis across market conditions
- **Comprehensive Analytics**: 11+ analysis modules for trading decisions

---

## ðŸŽ¯ Core Features

### Deep Learning Models (PyTorch 2.x)

#### 1. **LSTM (Long Short-Term Memory)**
- **Parameters**: 34,301 trainable
- **Architecture**: Multi-layer LSTM with dropout
- **Best For**: Sequential pattern recognition
- **Performance**: Strong baseline performance

#### 2. **Attention-LSTM**
- **Parameters**: 59,330 trainable
- **Architecture**: LSTM with attention mechanism
- **Best For**: Capturing long-term dependencies
- **Performance**: Improved accuracy on trend changes

#### 3. **N-BEATS (Neural Basis Expansion Analysis)**
- **Parameters**: 2,718,244 trainable
- **Architecture**: Double residual stacking with trend/seasonality decomposition
- **Best For**: Time series forecasting with interpretability
- **Performance**: Excellent on complex patterns

#### 4. **TCN (Temporal Convolutional Network)**
- **Parameters**: 56,225 trainable
- **Architecture**: Dilated causal convolutions
- **Best For**: Fast parallel processing
- **Performance**: Efficient on large datasets

#### 5. **Transformer**
- **Parameters**: 152,833 trainable
- **Architecture**: Multi-head self-attention
- **Best For**: Capturing complex temporal relationships
- **Performance**: Superior on volatile markets

#### 6. **Ensemble Model**
- **Strategy**: Weighted average of all models
- **Weights**: Dynamically adjusted based on performance
- **Best For**: Robust predictions across all conditions
- **Performance**: Most consistent results

### GPU Optimization
- **Mixed Precision Training**: Faster computation with FP16/FP32
- **cuDNN Benchmarking**: Optimized convolution algorithms
- **Automatic Device Detection**: CPU fallback when GPU unavailable
- **Memory Efficient**: Gradient accumulation for large models

---

## ï¿½ Advanced Analytics Modules

### 1. **Data & Analysis**
- Historical price data with multiple timeframes
- 20+ technical indicators (MA, RSI, MACD, Bollinger Bands, ATR, OBV, etc.)
- Volume analysis with moving averages
- Correlation matrices and statistical summaries
- Interactive candlestick charts with support/resistance levels

### 2. **Model Training**
- **Train Individual Models**: LSTM, Attention-LSTM, N-BEATS, TCN, Transformer
- **Train All Models**: Batch training with comparison
- **Hyperparameter Tuning**: Sequence length, epochs, batch size, learning rate
- **Real-Time Metrics**: Live training progress with loss curves
- **Early Stopping**: Prevent overfitting with patience parameter
- **Model Architecture Display**: Detailed layer information
- **Performance Metrics**: RMSE, MAE, MAPE, RÂ², Direction Accuracy

### 3. **Predictions & Forecasting**
- **Multi-Model Predictions**: View predictions from all trained models
- **Unified Visualizations**: Combined graphs for model comparison
- **Confidence Intervals**: Prediction uncertainty quantification
- **Error Analysis**: Per-model error distribution
- **Residual Analysis**: Diagnostic plots
- **Future Forecasting**: 1-60 day forecasts with trend visualization

### 4. **Real-Time Monitor** ðŸ”¥ NEW
- **Google Finance Style Interface**: Professional, familiar design
- **Live Price Updates**: Real-time quote data with auto-refresh
- **Period Selector**: 1D, 5D, 1M, 6M, YTD, 1Y, 5Y, Max
- **Dynamic Charts**: Gradient-filled charts (green/red based on performance)
- **Key Statistics Grid**: Open, High, Low, Market Cap, P/E Ratio, 52-week range, Volume, Average Volume
- **Next-Day Predictions**: AI forecast with configurable parameters
- **Model Selection**: Choose any trained model for predictions
- **Adjustable Settings**: Sequence length, data period, model selection

### 5. **Interactive Candlestick Charts** ðŸ”¥ NEW
- **OHLC Visualization**: Interactive candlestick patterns
- **Volume Subplot**: Trading volume analysis
- **Support & Resistance**: Automated level detection using scipy
- **Pattern Annotations**: 7 candlestick patterns (Doji, Hammer, Shooting Star, Engulfing, Star patterns)
- **Zoom & Pan**: Plotly-powered interactions

### 6. **Model Comparison Dashboard** ðŸ”¥ NEW
- **Side-by-Side Metrics**: Compare all models simultaneously
- **Error Distribution**: Box plots showing prediction accuracy
- **Market Condition Analysis**: Performance across low/medium/high volatility
- **Best Model Identification**: Automatic highlighting
- **Visual Insights**: 3 comprehensive comparison charts

### 7. **Trading Signals**
- RSI overbought/oversold detection
- MACD momentum and trend signals
- Moving average crossovers (Golden/Death Cross)
- Bollinger Bands breakout signals
- Volume anomaly detection
- Overall recommendation with confidence scores

### 8. **Multi-Stock Comparison**
- Compare 2-3 stocks simultaneously
- Normalized performance charts
- Side-by-side metrics (returns, volatility, RSI)
- Correlation analysis
- Excel export

### 9. **Virtual Portfolio Tracker**
- Paper trading with $100,000 starting capital
- Real-time P&L tracking
- Transaction management (buy/sell with commissions)
- Performance metrics (win rate, average win/loss)
- Holdings dashboard
- Complete transaction history

### 10. **Risk Metrics Dashboard**
- Value at Risk (VaR) at 95% and 99% confidence
- Conditional VaR (CVaR) for tail risk
- Maximum Drawdown analysis
- Sharpe, Sortino, and Calmar ratios
- Beta and volatility metrics
- Risk rating system (Low/Moderate/High/Very High)
- Interactive drawdown charts

### 11. **Pattern Recognition**
- 7 candlestick patterns (Doji, Hammer, Shooting Star, Engulfing, Morning/Evening Star)
- Automated support/resistance detection
- Pattern signals (BULLISH/BEARISH/NEUTRAL)
- 30-day pattern frequency analysis
- Educational descriptions

### 12. **Reports & Export**
- Comprehensive analysis reports
- Executive summaries
- Multi-format exports (TXT, CSV, Excel)
- Key findings and recommendations

---

## ðŸ“ Project Structure

```
ELEVATE-1/
â”‚
â”œâ”€â”€ app.py                          # Main Streamlit application (4900+ lines)
â”œâ”€â”€ config.py                       # Configuration and hyperparameters
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ environment.yml                 # Conda environment specification
â”œâ”€â”€ README.md                       # Documentation (this file)
â”œâ”€â”€ NBEATS_INTEGRATION.md          # N-BEATS implementation guide
â”œâ”€â”€ Stock_Prediction_System_Report.md  # Technical report
â”‚
â”œâ”€â”€ data/                           # Data storage directory
â”‚   â””â”€â”€ (Stock data cached here)
â”‚
â”œâ”€â”€ models/                         # Trained model storage (.pth files)
â”‚   â”œâ”€â”€ lstm_stock_model.pth       # LSTM model weights
â”‚   â”œâ”€â”€ attention_lstm_model.pth   # Attention-LSTM weights
â”‚   â”œâ”€â”€ nbeats_model.pth           # N-BEATS weights
â”‚   â”œâ”€â”€ tcn_model.pth              # TCN weights
â”‚   â”œâ”€â”€ transformer_model.pth      # Transformer weights
â”‚   â”œâ”€â”€ ensemble_model.pth         # Ensemble weights
â”‚   â”œâ”€â”€ feature_scaler.pkl         # Feature normalization scaler
â”‚   â””â”€â”€ target_scaler.pkl          # Target normalization scaler
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ notebooks_stock_price_prediction_Version2_.ipynb
â”‚
â””â”€â”€ src/                            # Source code modules
    â”œâ”€â”€ __init__.py                # Package initialization
    â”‚
    â”œâ”€â”€ data_fetcher.py            # Stock data retrieval + real-time quotes
    â”œâ”€â”€ feature_engineering.py     # 20+ technical indicators
    â”œâ”€â”€ preprocessor.py            # Data preprocessing and normalization
    â”‚
    â”œâ”€â”€ model.py                   # LSTM model (PyTorch)
    â”œâ”€â”€ attention_lstm_model.py    # Attention-LSTM (PyTorch)
    â”œâ”€â”€ nbeats_model.py            # N-BEATS (PyTorch)
    â”œâ”€â”€ tcn_model.py               # Temporal Convolutional Network
    â”œâ”€â”€ transformer_model.py       # Transformer (PyTorch)
    â”œâ”€â”€ trainer.py                 # Model training logic (GPU-optimized)
    â”œâ”€â”€ nbeats_trainer.py          # N-BEATS specific trainer
    â”‚
    â”œâ”€â”€ visualizer.py              # Charts and visualizations
    â”œâ”€â”€ trading_signals.py         # Signal generation
    â”œâ”€â”€ portfolio_manager.py       # Portfolio tracking
    â”œâ”€â”€ risk_metrics.py            # Risk calculations
    â””â”€â”€ pattern_recognition.py     # Pattern detection
```

---

## ðŸ“„ Key File Documentation

### **`app.py`** (Main Application - 4900+ lines)

The central Streamlit application orchestrating all components.

**Architecture:**
- **Lines 1-50**: Imports, GPU detection, logging setup
- **Lines 51-400**: CSS styling, Google Finance-inspired UI
- **Lines 401-550**: Sidebar (stock selection, model parameters)
- **Lines 551-700**: Model auto-loading (PyTorch state dicts)
- **Lines 701-4900**: 13 Tab implementations

**Tab Structure:**
1. **Data & Analysis** (700-950): Technical indicators, candlestick charts
2. **Model Training** (951-1800): Individual/batch training, hyperparameters
3. **Prediction** (1801-2400): Multi-model predictions, unified visualizations
4. **Forecast** (2401-2800): Multi-day forecasting
5. **Trading Signals** (2801-3100): RSI, MACD, MA crossovers
6. **Stock Comparison** (3101-3400): Multi-stock analysis
7. **Portfolio** (3401-3700): Paper trading tracker
8. **Real-Time Monitor** (3701-4400): Google Finance UI, live updates ðŸ”¥
9. **Risk Metrics** (4401-4600): VaR, drawdown, Sharpe ratio
10. **Pattern Recognition** (4601-4750): Candlestick patterns
11. **Reports** (4751-4800): Export functionality

---

### **`config.py`** (Configuration)

Model hyperparameters and system settings.

**Key Settings:**
```python
# Model Configuration
SEQUENCE_LENGTH = 60        # Lookback window
EPOCHS = 50                 # Training iterations
BATCH_SIZE = 32             # Mini-batch size
LEARNING_RATE = 0.001       # Adam optimizer
DROPOUT_RATE = 0.2          # Regularization

# GPU Settings
USE_MIXED_PRECISION = True  # FP16/FP32 training
CUDA_BENCHMARK = True       # cuDNN optimization

# Features (20+ indicators)
FEATURES = [
    'Close', 'Volume', 'MA_10', 'MA_50', 'MA_200',
    'RSI_14', 'MACD', 'MACD_Signal', 'MACD_Diff',
    'BB_Upper', 'BB_Middle', 'BB_Lower', 'ATR',
    'OBV', 'Returns', 'Volatility_20', ...
]
```
```

**Purpose:**
- Centralized parameter management
- Easy hyperparameter tuning
- Consistent configuration across modules

---

#### **`requirements.txt`** (Dependencies)

Complete list of Python packages required for the application.

**Core Dependencies:**
```
streamlit>=1.25.0           # Web framework
pandas>=1.5.0               # Data manipulation
numpy>=1.23.0               # Numerical computing
tensorflow>=2.10.0          # Deep learning
keras>=2.10.0               # Neural network API
```

**Data & Visualization:**
```
yfinance>=0.2.0             # Stock data API
plotly>=5.14.0              # Interactive charts
matplotlib>=3.5.0           # Static plots
seaborn>=0.12.0             # Statistical plots
```

**Technical Analysis:**
```
scikit-learn>=1.2.0         # ML utilities
scipy>=1.10.0               # Statistical functions
```

**Advanced Features:**
```
requests>=2.31.0            # HTTP requests
```

**Export & Storage:**
```
openpyxl>=3.0.0             # Excel export
xlsxwriter>=3.0.0           # Excel formatting
```

---

### Source Code Modules (`src/`)

#### **`data_fetcher.py`** (228 lines)

**Class:** `StockDataFetcher`

Handles all stock data retrieval from Yahoo Finance API.

**Key Methods:**
```python
def fetch_stock_data(ticker, period='1y', interval='1d'):
    """
    Download stock data from Yahoo Finance
    
    Args:
        ticker (str): Stock symbol (e.g., 'AAPL')
        period (str): Time period (1mo, 3mo, 6mo, 1y, 2y, 5y, max)
        interval (str): Data granularity (1d, 1wk, 1mo)
    
    Returns:
        pd.DataFrame: OHLCV data with DateTimeIndex
    """

def get_stock_info(ticker):
    """
    Fetch company information and metadata
    
    Returns:
        dict: Company name, sector, market cap, etc.
    """

def validate_ticker(ticker):
    """
    Check if ticker symbol is valid
    
    Returns:
        bool: True if ticker exists
    """
```

**Features:**
- Automatic retry logic with exponential backoff
- Error handling for invalid tickers
- Data validation and cleaning
- Missing data interpolation
- Timezone handling

**Error Handling:**
- Invalid ticker symbols
- Network connectivity issues
- API rate limiting
- Missing or corrupt data

---

#### **`feature_engineering.py`** (456 lines)

**Class:** `FeatureEngineer`

Calculates 20+ technical indicators for stock analysis.

**Technical Indicators Implemented:**

1. **Moving Averages:**
   - Simple Moving Average (SMA): 10, 50, 200 days
   - Exponential Moving Average (EMA): 12, 26 days

2. **Momentum Indicators:**
   - RSI (Relative Strength Index): 14-day period
   - MACD (Moving Average Convergence Divergence)
   - MACD Signal Line
   - MACD Histogram
   - Stochastic Oscillator

3. **Volatility Indicators:**
   - Bollinger Bands (Upper, Middle, Lower)
   - Average True Range (ATR)
   - Standard Deviation

4. **Volume Indicators:**
   - On-Balance Volume (OBV)
   - Volume Moving Average
   - Volume Rate of Change

5. **Trend Indicators:**
   - ADX (Average Directional Index)
   - Parabolic SAR

**Key Methods:**
```python
def add_all_features(df):
    """
    Add all technical indicators to dataframe
    
    Returns:
        pd.DataFrame: Enhanced with 20+ indicators
    """

def calculate_rsi(prices, period=14):
    """Calculate Relative Strength Index"""

def calculate_macd(prices, fast=12, slow=26, signal=9):
    """Calculate MACD and signal line"""

def calculate_bollinger_bands(prices, period=20, std_dev=2):
    """Calculate Bollinger Bands"""
```

**Data Quality:**
- Handles missing values with forward fill
- Normalizes indicators to [0, 1] range
- Removes NaN values after calculations
- Validates data integrity

---

#### **`preprocessor.py`** (312 lines)

**Class:** `DataPreprocessor`

Prepares data for LSTM model training and inference.

**Key Responsibilities:**

1. **Data Scaling:**
```python
def scale_data(df, feature_columns):
    """
    MinMaxScaler normalization to [0, 1]
    
    Returns:
        scaled_data: Normalized features
        scaler: Fitted scaler object for inverse transform
    """
```

2. **Sequence Creation:**
```python
def create_sequences(data, sequence_length=60):
    """
    Create sliding windows for time series
    
    Args:
        data: Scaled feature data
        sequence_length: Lookback period
    
    Returns:
        X: Input sequences (samples, timesteps, features)
        y: Target values (next day's price)
    """
```

3. **Train-Test Split:**
```python
def split_data(X, y, train_ratio=0.8):
    """
    Temporal split preserving order
    
    Returns:
        X_train, X_test, y_train, y_test
    """
```

**Features:**
- Maintains temporal order (no shuffling)
- Handles multiple features (multivariate)
- Preserves scaler for inverse transformation
- Memory-efficient processing
- Validates sequence lengths

---

#### **`model.py`** (267 lines)

**Class:** `LSTMModel`

Defines the LSTM neural network architecture.

**Model Architecture:**
```python
Input Layer: (sequence_length, num_features)
    â†“
LSTM Layer 1: 128 units, return_sequences=True
    â†“
Dropout: 0.2
    â†“
LSTM Layer 2: 64 units, return_sequences=True
    â†“
Dropout: 0.2
    â†“
LSTM Layer 3: 32 units
    â†“
Dropout: 0.2
    â†“
Dense Layer: 1 unit (price prediction)
```

**Key Methods:**
```python
def build_model(input_shape, lstm_units=[128, 64, 32], dropout=0.2):
    """
    Construct LSTM model with configurable architecture
    
    Args:
        input_shape: (sequence_length, num_features)
        lstm_units: List of units per LSTM layer
        dropout: Dropout rate for regularization
    
    Returns:
        Compiled Keras model
    """

def compile_model(learning_rate=0.001):
    """
    Compile with Adam optimizer and MSE loss
    """
```

**Optimizer:**
- Adam optimizer with configurable learning rate
- MSE (Mean Squared Error) loss function
- MAE (Mean Absolute Error) metric

**Regularization:**
- Dropout layers (20% default) to prevent overfitting
- Early stopping callback
- Learning rate reduction on plateau

---

#### **`trainer.py`** (389 lines)

**Class:** `ModelTrainer`

Handles model training, validation, and evaluation.

**Training Pipeline:**

1. **Training Loop:**
```python
def train_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32):
    """
    Train with callbacks and validation
    
    Callbacks:
        - EarlyStopping: Stop if no improvement
        - ModelCheckpoint: Save best model
        - ReduceLROnPlateau: Adjust learning rate
    
    Returns:
        history: Training metrics
        best_model_path: Path to saved model
    """
```

2. **Evaluation Metrics:**
```python
def evaluate_model(model, X_test, y_test, scaler):
    """
    Calculate comprehensive metrics
    
    Metrics:
        - RMSE: Root Mean Squared Error
        - MAE: Mean Absolute Error
        - MAPE: Mean Absolute Percentage Error
        - RÂ² Score: Coefficient of determination
        - Direction Accuracy: Trend prediction accuracy
    
    Returns:
        dict: All metric values
    """
```

3. **Visualization:**
```python
def plot_training_history(history):
    """Plot loss curves for training and validation"""

def plot_predictions(actual, predicted):
    """Overlay predictions on actual prices"""
```

**Features:**
- Real-time progress tracking in Streamlit
- Model checkpointing (saves best performing model)
- Early stopping to prevent overfitting
- Learning rate scheduling
- Comprehensive metric calculation

---

#### **`visualizer.py`** (523 lines)

**Class:** `Visualizer`

Creates all charts and visualizations using Plotly.

**Chart Types:**

1. **Candlestick Charts:**
```python
def plot_candlestick(df, title="Stock Price"):
    """
    OHLC candlestick with volume subplot
    Features: Zoom, pan, hover, range selector
    """
```

2. **Technical Indicator Overlays:**
```python
def plot_with_indicators(df, indicators=['MA_50', 'MA_200', 'RSI']):
    """
    Price chart with indicator overlays and subplots
    """
```

3. **Comparison Charts:**
```python
def plot_multi_stock(dfs, tickers):
    """
    Normalized comparison of multiple stocks
    """
```

4. **Statistical Plots:**
```python
def plot_correlation_matrix(df):
    """Heatmap of feature correlations"""

def plot_distribution(data, title):
    """Histogram with KDE overlay"""
```

**Styling:**
- Consistent color scheme (purple gradient)
- Responsive layout
- Interactive tooltips
- Professional typography
- Dark mode compatible

---

#### **`trading_signals.py`** (471 lines)

**Class:** `TradingSignals`

Generates actionable buy/sell/hold signals.

**Signal Generation Logic:**

1. **RSI Signals:**
```python
def get_rsi_signal(rsi_value):
    """
    RSI < 30: BUY (Oversold)
    RSI > 70: SELL (Overbought)
    30 â‰¤ RSI â‰¤ 70: HOLD (Neutral)
    
    Returns:
        signal: BUY/SELL/HOLD
        strength: HIGH/MEDIUM/LOW
        reason: Explanation
    """
```

2. **MACD Signals:**
```python
def get_macd_signal(macd, signal_line):
    """
    MACD crosses above signal: BUY
    MACD crosses below signal: SELL
    """
```

3. **Moving Average Signals:**
```python
def get_ma_signal(price, ma_50, ma_200):
    """
    Golden Cross (MA50 > MA200): BUY
    Death Cross (MA50 < MA200): SELL
    """
```

4. **Bollinger Bands:**
```python
def get_bollinger_signal(price, upper_band, lower_band):
    """
    Price touches lower band: BUY (Oversold)
    Price touches upper band: SELL (Overbought)
    """
```

5. **Volume Analysis:**
```python
def get_volume_signal(current_vol, avg_vol):
    """
    High volume + price increase: STRONG BUY
    High volume + price decrease: STRONG SELL
    """
```

**Aggregated Signal:**
```python
def get_comprehensive_signals(df):
    """
    Combine all signals with weighting
    
    Returns:
        overall_recommendation: STRONG BUY/BUY/HOLD/SELL/STRONG SELL
        confidence: 0-100%
        buy_score: Bullish strength
        sell_score: Bearish strength
        individual_signals: Breakdown per indicator
    """
```

---

#### **`portfolio_manager.py`** (336 lines)

**Class:** `PortfolioManager`

Manages virtual trading portfolio with paper money.

**Core Features:**

1. **Portfolio Initialization:**
```python
def __init__(self, initial_cash=100000):
    """
    Start with $100,000 virtual capital
    
    Attributes:
        cash: Available liquid cash
        holdings: Dict of stock positions
        transactions: List of all trades
        commission: $10 per trade
    """
```

2. **Trading Functions:**
```python
def buy_stock(ticker, shares, price):
    """
    Execute buy order
    
    Validations:
        - Sufficient cash
        - Positive share quantity
        - Valid price
    
    Updates:
        - Deduct cash (price * shares + commission)
        - Add/update holdings
        - Record transaction
    """

def sell_stock(ticker, shares, price):
    """
    Execute sell order
    
    Validations:
        - Sufficient shares owned
        - Valid ticker in holdings
    
    Updates:
        - Add cash (price * shares - commission)
        - Remove/update holdings
        - Record transaction with P/L
    """
```

3. **Portfolio Valuation:**
```python
def get_portfolio_value(current_prices):
    """
    Calculate total portfolio worth
    
    Returns:
        total_value: Cash + holdings value
        holdings_value: Market value of positions
        total_return: P/L in dollars
        total_return_pct: P/L percentage
    """
```

4. **Performance Metrics:**
```python
def get_performance_metrics(current_prices):
    """
    Trading statistics
    
    Metrics:
        - Win rate: % of profitable trades
        - Wins/Losses: Count of each
        - Average win: Mean profit per winning trade
        - Average loss: Mean loss per losing trade
    """
```

5. **Data Export:**
```python
def get_holdings_df(current_prices):
    """DataFrame of current positions"""

def get_transactions_df():
    """DataFrame of trade history"""
```

**Position Tracking:**
- Average cost basis calculation
- Real-time P&L for each position
- Percentage gain/loss per stock
- Total portfolio diversification

---

#### **`risk_metrics.py`** (347 lines)

**Class:** `RiskAnalyzer`

Calculates comprehensive risk and performance metrics.

**Risk Metrics:**

1. **Value at Risk (VaR):**
```python
def calculate_var(returns, confidence=0.95):
    """
    Historical VaR calculation
    
    Args:
        returns: Daily return series
        confidence: 0.95 or 0.99
    
    Returns:
        VaR: Maximum expected loss at confidence level
    
    Example:
        VaR(95%) = -2.5% means 95% confidence that 
        loss won't exceed 2.5% in one day
    """
```

2. **Conditional Value at Risk (CVaR):**
```python
def calculate_cvar(returns, confidence=0.95):
    """
    Expected loss beyond VaR threshold
    
    Returns:
        CVaR: Average loss in worst (1-confidence)% of cases
    """
```

3. **Maximum Drawdown:**
```python
def calculate_max_drawdown(prices):
    """
    Largest peak-to-trough decline
    
    Returns:
        max_drawdown: Percentage decline
        peak_date: Date of peak price
        trough_date: Date of lowest price
        recovery_date: Date when price recovered (or None)
        drawdown_series: Full drawdown history
    """
```

4. **Sharpe Ratio:**
```python
def calculate_sharpe_ratio(returns, risk_free_rate=0.02):
    """
    Risk-adjusted return metric
    
    Formula:
        (Return - RiskFreeRate) / Volatility
    
    Interpretation:
        > 2: Excellent
        > 1: Good
        > 0: Acceptable
        < 0: Poor (losing money)
    """
```

5. **Sortino Ratio:**
```python
def calculate_sortino_ratio(returns, risk_free_rate=0.02):
    """
    Similar to Sharpe but only penalizes downside volatility
    
    Better for asymmetric return distributions
    """
```

6. **Calmar Ratio:**
```python
def calculate_calmar_ratio(returns, prices):
    """
    Annual return / Maximum drawdown
    
    Higher is better
    Shows return relative to worst drawdown
    """
```

7. **Beta:**
```python
def calculate_beta(stock_returns, market_returns):
    """
    Systematic risk vs market (S&P 500)
    
    Beta = 1: Moves with market
    Beta > 1: More volatile than market
    Beta < 1: Less volatile than market
    Beta < 0: Moves opposite to market
    """
```

**Risk Rating System:**
```python
def get_risk_rating(metrics):
    """
    Overall risk assessment
    
    Scoring based on:
        - Volatility (lower is better)
        - Sharpe Ratio (higher is better)
        - Max Drawdown (smaller is better)
    
    Ratings:
        - Low Risk: Score â‰¥ 80%
        - Moderate Risk: 60% â‰¤ Score < 80%
        - High Risk: 40% â‰¤ Score < 60%
        - Very High Risk: Score < 40%
    """
```

---

#### **`pattern_recognition.py`** (348 lines)

**Class:** `PatternRecognizer`

Detects candlestick patterns and chart levels.

**Candlestick Patterns:**

1. **Doji:**
```python
def detect_doji(df, threshold=0.1):
    """
    Open â‰ˆ Close (body < 10% of range)
    
    Significance:
        - Indecision pattern
        - Potential reversal signal
        - Context-dependent (trend reversal or continuation)
    """
```

2. **Hammer (Bullish):**
```python
def detect_hammer(df):
    """
    Criteria:
        - Small body at top
        - Long lower shadow (2x body)
        - Little/no upper shadow
    
    Significance:
        - Bullish reversal at downtrend bottom
        - Buyers rejected lower prices
    """
```

3. **Shooting Star (Bearish):**
```python
def detect_shooting_star(df):
    """
    Criteria:
        - Small body at bottom
        - Long upper shadow (2x body)
        - Little/no lower shadow
    
    Significance:
        - Bearish reversal at uptrend top
        - Sellers rejected higher prices
    """
```

4. **Engulfing Patterns:**
```python
def detect_engulfing(df):
    """
    Bullish Engulfing:
        - Large green candle fully engulfs previous red candle
        - Strong reversal signal at bottom
    
    Bearish Engulfing:
        - Large red candle fully engulfs previous green candle
        - Strong reversal signal at top
    """
```

5. **Morning Star (Bullish):**
```python
def detect_morning_star(df):
    """
    Three-candle pattern:
        1. Large bearish candle
        2. Small indecision candle (Doji/Spinning Top)
        3. Large bullish candle
    
    Significance:
        - Strong bottom reversal
        - Shift from selling to buying pressure
    """
```

6. **Evening Star (Bearish):**
```python
def detect_evening_star(df):
    """
    Three-candle pattern:
        1. Large bullish candle
        2. Small indecision candle
        3. Large bearish candle
    
    Significance:
        - Strong top reversal
        - Shift from buying to selling pressure
    """
```

**Support & Resistance:**
```python
def detect_support_resistance(df, window=20):
    """
    Identify key price levels
    
    Method:
        1. Find local minima (support) and maxima (resistance)
        2. Cluster nearby levels
        3. Rank by frequency of touches
    
    Returns:
        support: List of support prices (ascending)
        resistance: List of resistance prices (ascending)
    
    Usage:
        - Entry/exit points
        - Stop-loss placement
        - Breakout identification
    """
```

**Pattern Signals:**
```python
def get_pattern_signal(patterns_dict):
    """
    Aggregate pattern analysis
    
    Scoring:
        - Each pattern gets weight based on count
        - Bullish patterns add to bullish_score
        - Bearish patterns add to bearish_score
    
    Returns:
        signal: 'BULLISH', 'BEARISH', or 'NEUTRAL'
        strength: Percentage confidence (0-100%)
        description: Explanation
    """
```

---

## ðŸš€ Installation & Setup

### Prerequisites

- **Python**: 3.8+ (3.10+ recommended)
- **CUDA**: 11.8 or 12.x (for GPU support)
- **GPU**: NVIDIA GPU with 6GB+ VRAM (optional but recommended)
- **OS**: Windows, Linux, or macOS

### Option 1: Conda Environment (Recommended)

```bash
# Create environment from yml file
conda env create -f environment.yml
conda activate t5

# Or manually
conda create -n stock-pred python=3.10
conda activate stock-pred
```

### Option 2: Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS
python3 -m venv venv
source venv/bin/activate
```

### Step 1: Install PyTorch with CUDA

**For CUDA 13.x (RTX 40/50 series):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130
```

**For CUDA 11.8:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**For CPU only:**
```bash
pip install torch torchvision torchaudio
```

### Step 2: Install Dependencies

```bash
pip install -r requirements.txt
```

**Key Dependencies:**
```
streamlit>=1.25.0
torch>=2.0.0
pandas>=1.5.0
numpy>=1.23.0
yfinance>=0.2.0
plotly>=5.14.0
scikit-learn>=1.2.0
scipy>=1.10.0
openpyxl>=3.1.0
```

### Step 3: Verify GPU Setup (Optional)

```python
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"GPU Device: {torch.cuda.get_device_name(0)}")
print(f"CUDA Version: {torch.version.cuda}")
```

### Step 4: Download NLTK Data

```python
import nltk
nltk.download('brown')
nltk.download('punkt')
```

### Step 5: Launch Application

```bash
streamlit run app.py
```

App opens at `http://localhost:8501`

---

## ðŸ“– Quick Start Guide

### First Time Setup

1. **Launch App:**
   ```bash
   streamlit run app.py
   ```

2. **GPU Detection:**
   - App automatically detects CUDA GPU
   - Shows GPU name, memory, CUDA version
   - Falls back to CPU if no GPU available

3. **Select Stock:**
   - Sidebar: Enter ticker (AAPL, MSFT, TSLA, etc.)
   - Or use popular stocks dropdown

4. **Set Parameters:**
   - **Period**: 1y, 2y, 5y (data range)
   - **Sequence Length**: 60 (lookback days)
   - **Epochs**: 50 (training iterations)
   - **Batch Size**: 32
   - **Learning Rate**: 0.001

### Basic Workflow

#### 1. Data Analysis (Tab 1)
- View historical prices & volume
- Check 20+ technical indicators
- Interactive candlestick charts
- Support/resistance levels

#### 2. Model Training (Tab 2)

**Train Single Model:**
- Select model (LSTM, N-BEATS, etc.)
- Click "Train Model"
- Monitor real-time progress
- View architecture & metrics

**Train All Models:**
- Click "Train All Models"
- Batch training with comparison
- Architecture display for each
- Performance metrics side-by-side

#### 3. Predictions (Tab 3)
- Select models to compare
- View predictions vs actual prices
- Unified error analysis
- Confidence intervals
- Residual plots

#### 4. Real-Time Monitor (Tab 8) ðŸ”¥
- **Live Quotes**: Current price, change, volume
- **Period Charts**: 1D, 5D, 1M, 6M, YTD, 1Y, 5Y, Max
- **Statistics Grid**: Open, High, Low, Market Cap, P/E, 52-week range
- **AI Predictions**: 
  - Click "âš¡ Make Prediction"
  - Adjust settings (sequence length, data period)
  - Select model (LSTM, N-BEATS, etc.)
  - View next-day forecast with signal

#### 5. Advanced Features

**Trading Signals (Tab 5):**
- RSI overbought/oversold
- MACD crossovers
- Bollinger Band signals
- Overall BUY/SELL/HOLD recommendation

**Stock Comparison (Tab 6):**
- Compare 2-3 stocks
- Normalized performance
- Side-by-side metrics

**Portfolio Tracker (Tab 7):**
- Paper trading ($100K virtual)
- Buy/sell tracking
- Real-time P&L

**Risk Metrics (Tab 9):**
- VaR, CVaR, Max Drawdown
- Sharpe, Sortino, Calmar ratios
- Risk rating (Low/Moderate/High/Very High)

**Pattern Recognition (Tab 10):**
- 7 candlestick patterns
- Support/resistance detection
- Pattern signals

---

## ðŸŽ¯ Model Comparison Guide

### When to Use Each Model

**LSTM** - Best for:
- Baseline performance
- Quick training (34K params)
- Sequential patterns
- General market conditions

**Attention-LSTM** - Best for:
- Long-term dependencies
- Trend changes
- Important historical events
- 59K params, moderate speed

**N-BEATS** - Best for:
- Complex patterns
- Trend/seasonality decomposition
- High-capacity needs (2.7M params)
- When you have GPU

**TCN** - Best for:
- Fast parallel training
- Large datasets
- Real-time applications
- 56K params, efficient

**Transformer** - Best for:
- Volatile markets
- Complex temporal relationships
- Multi-scale patterns
- 153K params, GPU recommended

**Ensemble** - Best for:
- Most robust predictions
- Averaging out model weaknesses
- Critical decisions
- Combines all models
- Track real-time P/L
- Monitor win rates
- Export portfolio reports

**Risk Metrics:**
- Calculate VaR and CVaR
- Review drawdown analysis
- Check risk-adjusted ratios
- Assess overall risk rating
- Export risk report

**Pattern Recognition:**
- Detect candlestick patterns
- Identify support/resistance
- View pattern signals
- Export pattern analysis

---

## ðŸ”§ Configuration

### Model Hyperparameters

Edit `config.py` to customize:

```python
# Architecture
SEQUENCE_LENGTH = 60          # More = longer memory, slower training
LSTM_UNITS = [128, 64, 32]    # Larger = more capacity, risk of overfitting
DROPOUT_RATE = 0.2            # Higher = more regularization

# Training
EPOCHS = 50                   # More = better fit, longer training
BATCH_SIZE = 32               # Smaller = more updates, noisier gradients
LEARNING_RATE = 0.001         # Smaller = stable, slower convergence
```

### Customization

**Colors & Theme:**
- Edit CSS in `app.py` (lines 36-380)
- Modify color schemes in visualizer.py

**Technical Indicators:**
- Add new indicators in `feature_engineering.py`
- Update feature list in `config.py`

**Model Architecture:**
- Modify LSTM layers in `model.py`
- Experiment with GRU or Conv1D layers

---

## ðŸ“Š Performance Metrics Explained

### Model Metrics

**RMSE (Root Mean Squared Error):**
- Measures average prediction error
- Lower is better
- Same units as target (dollars)
- Penalizes large errors more

**MAE (Mean Absolute Error):**
- Average absolute prediction error
- Lower is better
- Less sensitive to outliers than RMSE

**MAPE (Mean Absolute Percentage Error):**
- Percentage-based error metric
- Scale-independent
- < 5%: Excellent
- < 10%: Good
- < 20%: Acceptable

**RÂ² Score (Coefficient of Determination):**
- Proportion of variance explained
- Range: -âˆž to 1
- > 0.9: Excellent fit
- > 0.8: Good fit
- > 0.7: Acceptable fit

**Direction Accuracy:**
- % of times trend direction is correct
- > 60%: Strong predictive power
- 50%: Random (coin flip)

### Trading Metrics

**Win Rate:**
```
Win Rate = (Winning Trades / Total Trades) Ã— 100%
```

**Average Win/Loss:**
```
Avg Win = Sum(Winning Trades) / Number of Wins
Avg Loss = Sum(Losing Trades) / Number of Losses
```

**Profit Factor:**
```
Profit Factor = Gross Profit / Gross Loss
> 1.5: Good strategy
```

### Risk Metrics

**Sharpe Ratio:**
```
Sharpe = (Return - Risk Free Rate) / Standard Deviation
> 2: Excellent
> 1: Good
> 0: Acceptable
```

**Sortino Ratio:**
```
Sortino = (Return - Risk Free Rate) / Downside Deviation
Better than Sharpe for asymmetric returns
```

**Calmar Ratio:**
```
Calmar = Annual Return / Maximum Drawdown
> 3: Excellent
> 1: Good
```

---

## ðŸ› Troubleshooting

### Common Issues

**1. Import Errors:**
```bash
ModuleNotFoundError: No module named 'streamlit'
```
**Solution:**
```bash
pip install -r requirements.txt
```

**2. NLTK Data Missing:**
```bash
LookupError: Resource 'punkt' not found
```
**Solution:**
```python
import nltk
nltk.download('punkt')
nltk.download('brown')
```

**3. Invalid Ticker:**
```
Error: Ticker symbol not found
```
**Solution:**
- Verify ticker symbol on Yahoo Finance
- Use correct exchange suffix (e.g., .L for London)

**4. Insufficient Data:**
```
Need at least 30 days of data
```
**Solution:**
- Select longer time period
- Choose more liquid stock
- Check if stock recently IPO'd

**5. Memory Error:**
```
MemoryError: Unable to allocate array
```
**Solution:**
- Reduce sequence length
- Decrease batch size
- Use shorter time period
- Close other applications

**6. Model Training Slow:**
**Solution:**
- Reduce epochs (e.g., 20-30)
- Increase batch size
- Use GPU if available (TensorFlow GPU)

**7. Pattern Recognition Error:**
```
Error: unhashable type 'dict'
```
**Solution:**
- Update to latest version
- Check data has OHLC columns
- Ensure sufficient data points (> 20 days)

---

## ðŸŽ“ Technical Details

### LSTM Architecture

**Why LSTM?**
- Handles sequential dependencies
- Avoids vanishing gradient problem
- Remembers long-term patterns
- Suitable for time series forecasting

**Architecture Details:**
```
Layer 1: LSTM(128 units, return_sequences=True)
  - Input: (batch, 60, features)
  - Output: (batch, 60, 128)
  - Params: ~67K

Layer 2: Dropout(0.2)
  - Randomly drops 20% of connections
  - Prevents overfitting

Layer 3: LSTM(64 units, return_sequences=True)
  - Output: (batch, 60, 64)
  - Params: ~49K

Layer 4: Dropout(0.2)

Layer 5: LSTM(32 units)
  - Output: (batch, 32)
  - Params: ~12K

Layer 6: Dropout(0.2)

Layer 7: Dense(1)
  - Output: (batch, 1) - price prediction
  - Params: 33

Total Parameters: ~128K
Trainable Parameters: ~128K
```

### Data Pipeline

```
Raw Stock Data (OHLCV)
    â†“
Feature Engineering (20+ indicators)
    â†“
Data Cleaning (remove NaN, outliers)
    â†“
Normalization (MinMaxScaler to [0, 1])
    â†“
Sequence Creation (sliding windows)
    â†“
Train/Test Split (80/20, temporal)
    â†“
Model Training (with validation)
    â†“
Predictions (inverse transform to original scale)
    â†“
Evaluation (RMSE, MAE, MAPE, RÂ², Direction)
```

### Technical Indicators Math

**RSI (Relative Strength Index):**
```
RS = Average Gain / Average Loss (over 14 days)
RSI = 100 - (100 / (1 + RS))

Interpretation:
  RSI > 70: Overbought
  RSI < 30: Oversold
```

**MACD:**
```
MACD = EMA(12) - EMA(26)
Signal = EMA(9) of MACD
Histogram = MACD - Signal

Signals:
  MACD crosses above Signal: Bullish
  MACD crosses below Signal: Bearish
```

**Bollinger Bands:**
```
Middle Band = SMA(20)
Upper Band = SMA(20) + (2 Ã— StdDev)
Lower Band = SMA(20) - (2 Ã— StdDev)

Signals:
  Price touches upper: Overbought
  Price touches lower: Oversold
  Band squeeze: Volatility breakout imminent
```

---

## ðŸš¦ Best Practices

### For Trading

1. **Never invest based solely on predictions**
2. **Use multiple timeframes** (short, medium, long-term)
3. **Combine with fundamental analysis**
4. **Set stop-losses** to limit downside
5. **Diversify portfolio** across sectors
6. **Paper trade first** before real money
7. **Monitor news and earnings** for context
8. **Use risk metrics** to assess exposure

### For Model Training

1. **Start with default parameters**
2. **Use longer training periods** (1y-2y) for better patterns
3. **Monitor validation loss** for overfitting
4. **Retrain periodically** as market conditions change
5. **Test on multiple stocks** to validate generalization
6. **Compare with simple baselines** (buy-and-hold)
7. **Document parameter changes** and results

### For Development

1. **Test on liquid stocks** (AAPL, MSFT, GOOGL)
2. **Validate data quality** before training
3. **Use version control** for experiments
4. **Log metrics** for comparison
5. **Profile performance** for optimization
6. **Write unit tests** for critical functions
7. **Document API changes**

---

## ðŸ“ˆ Performance Benchmarks

### Typical Metrics (on AAPL, 1y data, 50 epochs)

| Metric | Value | Interpretation |
|--------|-------|----------------|
| RMSE | $3.45 | Average error ~$3.45 |
| MAE | $2.71 | Typical deviation |
| MAPE | 1.8% | Excellent accuracy |
| RÂ² Score | 0.94 | Very good fit |
| Direction | 63% | Strong trend prediction |
| Training Time | 2-3 min | On CPU |

### Hardware Requirements

**Minimum:**
- CPU: Intel i5 or equivalent
- RAM: 8 GB
- Storage: 1 GB free space
- Internet: Stable connection

**Recommended:**
- CPU: Intel i7 or AMD Ryzen 7
- RAM: 16 GB
- GPU: NVIDIA GTX 1060+ (for faster training)
- Storage: 5 GB (for data caching)
- Internet: High-speed broadband

---

## ðŸ” Security & Privacy

### Data Privacy
- **No data stored on external servers**
- **All processing happens locally**
- **Stock data from public Yahoo Finance API**
- **No personal information collected**

### Recommendations
- **Don't share portfolio data** publicly
- **Use environment variables** for production API keys
- **Don't commit API keys** to version control
- **Use HTTPS** if deploying publicly

---


## ðŸ“„ License

MIT License - See LICENSE file for details

---

## âš ï¸ Disclaimer

**IMPORTANT: READ CAREFULLY**

This application is for **educational and research purposes only**.

- **Not financial advice**: Do not use predictions as sole basis for investment decisions
- **No guarantees**: Past performance doesn't indicate future results
- **Market risk**: You can lose money trading stocks
- **Professional advice**: Consult qualified financial advisors
- **No liability**: Developers not responsible for trading losses
- **Test thoroughly**: Paper trade extensively before risking real capital
- **Understand risks**: Stock trading involves substantial risk

**USE AT YOUR OWN RISK**

---


## ðŸ™ Acknowledgments

### Technologies
- **Streamlit**: Web framework
- **TensorFlow/Keras**: Deep learning
- **Yahoo Finance**: Stock data
- **Plotly**: Interactive charts
- **SciPy**: Statistical analysis

### Inspiration
- Financial ML research papers
- Trading community feedback
- Open source projects

---

## ðŸ“Š Project Stats

- **Lines of Code**: 4,700+
- **Modules**: 11
- **Features**: 40+
- **Charts**: 20+
- **Technical Indicators**: 20+
- **Candlestick Patterns**: 7
- **Risk Metrics**: 10+

---

## ðŸ”„ Version History

**Version 2.1** (Current)
- âœ… Migrated to PyTorch 2.x with CUDA 13.0
- âœ… Added 6 advanced models (LSTM, Attention-LSTM, N-BEATS, TCN, Transformer, Ensemble)
- âœ… GPU acceleration with mixed precision training
- âœ… Real-Time Monitor with Google Finance UI
- âœ… Configurable prediction parameters
- âœ… Enhanced candlestick charts with pattern recognition
- âœ… Model comparison dashboard
- âœ… Removed News Sentiment Analysis module

**Version 2.0**
- âœ… Added Risk Metrics Dashboard
- âœ… Added Pattern Recognition
- âœ… Enhanced portfolio tracker
- âœ… Improved error handling
- âœ… Sidebar navigation system

**Version 1.0**
- âœ… LSTM prediction model
- âœ… Technical indicators
- âœ… Trading signals
- âœ… Multi-stock comparison
- âœ… Virtual portfolio
- âœ… Excel exports

---

